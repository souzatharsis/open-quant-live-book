# Information Theory and Statistical Causality

We've all heard the say "correlation does not imply causation", but how can we quantify causation? This is an extremely difficult and often misleading task, particularly trying to infer causality from observational data and cannot perform controlled trials or A/B testing.

Take for example the 2-dimensional system from Fig. \@ref(fig:rand). At a first glance, one could say that there is no clear relationship or causality between the random variables $x_1$ and $x_2$. However, this apparent random system presents a causal relationship defined by the following simple equations: 
\begin{align*}
x_1 &= 0.441x_1 + \epsilon_1 \\
x_2 &= 0.51x_1^2 + \epsilon_2, \\ 
&\epsilon_1, \epsilon_2 \sim \mathcal{N}(0,1).
\end{align*}

A simple nonlinearity introduced in the relationship between $x_2$ and $x_1$ was enough to introduce enough complexity into the system and potentially mislead a naive (non-quant) human.

```{r rand, echo=FALSE, out.width='50%', fig.align = "center", fig.cap="Life is Random (or Nonlinear?)"}
knitr::include_graphics("./chapters/TransferEntropy/rand.png")
```


Fortunately, we can take advantage of statistics and information theory to uncover complex causal relationships from observational data (remember, this is still a very very challenging task). We quantify causality by using the notion of the causal relation introduced by Granger [@Wiener56; @granger:econ], where a signal $X$ is said to Granger-cause $Y$ if the future realizations of $Y$ can be better explained using the past information from $X$ and $Y$ rather than $Y$ alone.

In this Chapter, we will introduce a prediction-based definition of causality and its implementation using a vector auto-regression formulation. Next, we will introduce a probabilistic-definition of causality and its implementation using an information-theoretical framework. We will then symulate linear and nonlinear systems and uncover causal links with the proposed methods. In the final section, we will quantify information flow among global equity indexes further uncovering which indexes and markets are driving the global financial markets.

## A First Definition of Causality {#LinearG}

The most common definitions of Granger-causality (*G-causality*) rely on the prediction of a future 
value of the variable $Y$ by using the past values of $X$ and $Y$ itself. 
In that form, $X$ is said to *G-cause* $Y$ if the use of $X$ improves the prediction of $Y$.

Let $X_t$ be a random variable associated at time $t$ while $X^t$ represents the collection of random variables up to time $t$.
We consider ${X_t}, {Y_t}$ and ${Z_t}$ to be three stochastic processes. 
Let $\hat Y_{t+1}$ be a predictor for the value of the variable $Y$ at time $t+1$. 

We compare the expected value of a loss function $g(e)$ with the error $e=\hat{Y}_{t+1} - Y_{t+1}$ of two models: 

1. The expected value of the prediction error given only $Y^t$ 
\begin{equation}
 \mathcal{R}(Y^{t+1} \, | \, Y^t,Z^t) = \mathbb{E}[g(Y_{t+1} - f_1(X^{t},Z^t))]
\end{equation}
2. The expected value of the prediction error given $Y^t$ and $X^t$
\begin{equation}
 \mathcal{R}(Y^{t+1} \, | \, X^{t},Y^t,Z^t) = \mathbb{E}[g(Y_{t+1} - f_2(X^{t},Y^t,Z^t))].
\end{equation}

In both models, the functions $f_1(.)$ and $f_2(.)$ are chosen to minimize the expected value of the loss function.  In most cases, these functions are retrieved with linear and, possibly, with nonlinear regressions, neural networks etc. Typical forms for $g(.)$ are the $l1$- or $l2$-norms.

We can now provide our first definition of statistical causality under the Granger causal notion as follows:

```{definition G1}
$X$ does not Granger-cause $Y$ relative to side information $Z$ if and only if $\mathcal{R}(Y_{t+1} \; | \; X^t, Y^t, Z^t) = \mathcal{R}(Y_{t+1} \; | \; Y^t, Z^t)$.
```
<br />

Standard Granger-causality  tests  assume  a  functional form in the  relationship  among the causes and effects and are implemented by fitting autoregressive models [@Wiener56; @granger:econ].

Consider the linear vector-autoregressive (VAR) equations:
\begin{align}
Y(t) &= {\alpha} + \sum^k_{\Delta t=1}{{\beta}_{\Delta t} Y(t-\Delta t)} + \epsilon_t, (\#eq:AR11)\\
Y(t) &= \widehat{\alpha} + \sum^k_{\Delta t=1}{{\widehat{\beta}}_{\Delta t} Y(t-\Delta t)} +  \sum^k_{\Delta t=1}{{\widehat{\gamma}}_{\Delta t}X(t-\Delta t)}+ \widehat{\epsilon}_t, (\#eq:AR22)
\end{align}
where $k$ is the number of lags considered. Alternatively, you can choose your DL/SVM/RF/GLM method of choice to fit the model.

From Def \@ref(def:G1), $X$ does not G-cause $Y$ if and only if the prediction errors of $X$ in the restricted Eq. \@ref(eq:AR11) and unrestricted regression models Eq. \@ref(eq:AR22) are equal (i.e., they are statistically indistinguishable). A one-way ANOVA test can be utilized to test if the residuals from Eqs. \@ref(eq:AR11) and \@ref(eq:AR22) differ from each other significantly. When more than one lag $k$ is tested, a correction for multiple hypotheses testing should be applied, e.g. False Discovery Rate (FDR) or Bonferroni correction.


## A Probabilistic-Based Definition

A more general definition than Def. \@ref(def:G1) that does not depend on assuming prediction functions can be formulated by considering conditional probabilities.
A probabilistic definition of G-causality assumes that $Y_{t+1}$ and $X^{t}$ are independent given the 
past information $(X^{t}, Y^{t})$ if and only if
$p(Y_{t+1} \, | \, X^{t}, Y^{t}, Z^{t}) = p(Y_{t+1} \, | \, Y^{t}, Z^{t})$, 
where $p(. \, | \, .)$ represents the conditional probability distribution.
In other words, omitting past information from $X$ does not change the probability distribution of $Y$. This leads to our second definition of statistical causality as follows:

```{definition G2}
$X$ does not Granger-cause $Y$ relative to side information $Z$ if and only if $Y_{t+1} \independent X^{t} \; | \; Y^{t}, Z^{t}$.
```
<br />

Def. \@ref(def:G2) does not assume any functional form in the coupling between $X$ and $Y$. 
Nevertheless, it requires a method to assess their conditional dependency. 
In the next section, we will leverage an Information-Theoretical framework for that purpose.


## Transfer Entropy and Statistical Causality {#nonlinearG}

Given a coupled system $(X,Y)$, where $P_Y(y)$ is the pdf of the random variable $Y$ and $P_{X,Y}$ is the joint pdf between $X$ and $Y$, 
the joint entropy between $X$ and $Y$ is given by the following:
\begin{equation}
H(X,Y) = -\sum_{x \in X}{\sum_{y \in Y}{P_{X,Y}(x,y)\log{P_{X,Y}(x,y)}}}.
\label{eq:HXY}
\end{equation}

The conditional entropy is defined by the following:
\begin{equation}
H\left(Y\middle\vert X\right) = H(X,Y) - H(X).
\end{equation}
We can interpret $H\left(Y\middle\vert X\right)$ as the uncertainty of $Y$ given a realization of $X$.


To compute G-Causality, we use the concept of Transfer Entropy. Since its introduction [@PhysRevLett.85.461], Transfer Entropy has been recognized as an important tool in the analysis of causal relationships in nonlinear systems [@citeulike:1447442].
It detects directional and dynamical information [@10.1371/journal.pone.0109462] while not assuming any particular functional form to describe interactions among systems.


The Transfer Entropy can be defined as the difference between the conditional entropies: 
\begin{equation}
 TE\left(X \rightarrow Y\right \vert Z) =  H\left(Y^F\middle\vert Y^P,Z^P\right) - H\left(Y^F\middle\vert X^P, Y^P,Z^P\right),
(\#eq:TE)
\end{equation}
which can be rewritten as a sum of Shannon entropies:
\begin{align}
TE\left(X \rightarrow Y\right) = H\left(Y^P, X^P\right) - H\left(Y^F, Y^P, X^P\right) + H\left(Y^F, Y^P\right) - H\left(Y^P\right),
\end{align}

where $Y^F$ is a forward time-shifted version of $Y$ at lag $\Delta t$ relatively to the past time-series $X^P$,  $Y^P$ and $Z^P$.
Within this framework we say that $X$ does not G-cause $Y$ relative to side information $Z$ if and only if 
$H\left(Y^F\middle\vert Y^P,Z^P \right) = H\left(Y^F\middle\vert X^P, Y^P,Z^P\right)$, i.e., when $TE\left(X \rightarrow Y,Z^P\right) = 0$.

<!-- Empirically, we reject this null hypothesis of causality if the Transfer Entropy from $X$ to $Y$ is significantly higher than the shuffled version of the original data. -->

<!-- For this we estimate 400 replicates of $TE(X_{Shuffled} \rightarrow Y)$, where $X_{Shuffled}$ is a random permutation of $X$ relatively to $Y$. -->
<!-- We compute the randomized Transfer Entropy at each permutation for each time-shift ($\Delta t$) from 1 to 10 days.  -->
<!-- We then calculated the frequency at which the observed Transfer Entropy was equal or more extreme  -->
<!-- than the randomized Transfer Entropy. The statistical significance was assessed using p-value $< 0.05$ after Bonferroni correction. -->


## Net Information Flow

Transfer-entropy is an asymmetric measure, i.e., $T_{X \rightarrow Y} \neq T_{Y \rightarrow X}$, and it thus allows the quantification of the directional coupling between systems. 
The Net Information Flow is defined as 
\begin{equation}
\widehat{TE}_{X \rightarrow Y} = TE_{X \rightarrow Y} - TE_{Y \rightarrow X}\;.
\end{equation}
One can interpret this quantity as a measure of the dominant direction of the information flow. In other words,
a positive result indicates a dominant information flow from $X$ to $Y$ compared to the other direction
or, similarly, it indicates which system provides more predictive information about the other system [@Michalowicz:2013:HDE:2601840].

## The Link Between Granger-causality and Transfer Entropy

It has been shown [@PhysRevLett.103.238701] that linear G-causality and Transfer Entropy are equivalent 
if all processes are jointly Gaussian.
In particular, by assuming the standard measure ($l2$-norm loss function) of linear G-causality for the bivariate case as follows (see Section \@ref(LinearG) for more details on linear-Granger causality):

\begin{equation}
GC_{X \rightarrow Y} = \log\left( \frac{var(\epsilon_t)}{var( \widehat{\epsilon}_t)} \right),
(\#eq:GCGC)
\end{equation}

the following can be proved [@PhysRevLett.103.238701]:

\begin{align}
TE_{X \rightarrow Y} = GC_{X \rightarrow Y}/2.
(\#eq:GCGC2)
\end{align}

This result provides a direct mapping between the Transfer Entropy and the linear G-causality implemented in the standard VAR framework.
Hence, it is possible to estimate the TE both in its general form and with its equivalent form for linear G-causality. 

## Empirical Experiment: Information Flow on Simulated Systems

In this section, we construct simulated systems to couple random variables in a causal manner.
We then quantify information flow using the methods studied in this Chapter.

We first assume a linear system, where random variables have linear relationships defined as follow:
\begin{align}
x_1(n) &= 0.95\sqrt{2}x_1(n-1) - 0.9025x_1(n-1) + w_1\\ \nonumber
x_2(n) &= 0.5x_1(n-1) + w_2\\ \nonumber
x_3(n) &= -0.4x_1(n-1) + w_3\\ \nonumber
x_4(n) &= -0.5x_1(n-1) + 0.25\sqrt{2}x_4(n-1) + 0.25\sqrt{2}x_5(n-1) + w_4\\ \nonumber
x_5(n) &= -0.25\sqrt{2}x_4(n-1) + 0.25\sqrt{2}x_5(n-1) + w_5, \nonumber
\end{align}
where $w_1, w_2, w_3, w_4, w_5 \sim N(0, 1)$. To simulate this system we assume $x_i(0) = 0, i \in (1, 2, \ldots, 5)$ as initial condition and then iteratively generate $x_i$ for $n \in (1, 2, \ldots, N)$ with a total of $N = 200,000$ iterations by randomly sampling $w_i, i \in (1, 2, \ldots, 5)$ from a normal distribution with zero mean and unit variance. 

The Fig. \@ref{fig:causality-graph1} A) represents the dependencies of the simulated linear system. 
The Fig. \ref{fig:causality-graph1} B) and Fig. \ref{fig:causality-graph1} C) show the linear and nonlinear Information Flows among the system's variables, respectively.
A cell $(x, y)$ presents the information flow from variable $y$ to variable $x$.
From Fig. \ref{fig:causality-graph1}, we observe that both the linear and nonlinear approaches presented similar results, i.e., both methods captured the system's dependencies similarly. 
This result is expected as the system is purely linear and the nonlinear information flow is able to capture both the linear and nonlinear interactions.
```{r causality-graph1, echo=FALSE, out.width='100%', fig.align = "center",fig.cap="Interactions between the variables of the simulated linear system."}
knitr::include_graphics("./chapters/TransferEntropy/S4Fig1.png")
```



We define a second system by introducing nonlinear interactions between $x_1$ and the variables $x_2$ and $x_5$ as follows:

\begin{align}
x_1(n) &= 0.95\sqrt{2}x_1(n-1) - 0.9025x_1(n-1) + w_1\\ \nonumber
x_2(n) &= \textcolor{red}{0.5x_1^2(n-1)} + w_2\\ \nonumber
x_3(n) &= -0.4x_1(n-1) + w_3\\ \nonumber
x_4(n) &= \textcolor{red}{-0.5x_1^2(n-1)} + 0.25\sqrt{2}x_4(n-1) + 0.25\sqrt{2}x_5(n-1) + w_4\\ \nonumber
x_5(n) &= -0.25\sqrt{2}x_4(n-1) + 0.25\sqrt{2}x_5(n-1) + w_5, \nonumber
\end{align}
where $w_1, w_2, w_3, w_4$ and $w_5 \sim N(0, 1)$. To simulate this system we assume $x_i(0) = 0, i \in (1, 2, ..., 5)$ as initial condition and then iteratively generate $x_i$ for $n \in (1, 2, ..., N)$ with a total of $N = 200,000$ iterations by randomly sampling $w_i, i \in (1, 2, ..., 5)$ from a normal distribution with zero mean and unit variance. 

The Fig. \ref{fig:C3S4Fig2} A) represents the dependencies of the simulated nonlinear system.
From Fig. \ref{fig:C3S4Fig2} B) and Fig. \ref{fig:C3S4Fig2} C), we observe that the nonlinear interactions introduced were not captured by the linear form of the information flow. 
While all linear interactions presented similar linear and nonlinear information flows, 
the two nonlinear interactions introduced in the system presented relatively higher nonlinear information flow compared to the linear formulation.

```{r C3S4Fig2, echo=FALSE, out.width='100%', fig.align = "center", fig.cap="Interactions between the variables of the simulated nonlinear system."}
knitr::include_graphics("./chapters/TransferEntropy/S4Fig2.png")
```

## Empirical Experiment: Information Flow on Global Markets
